{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "from pyvi import ViTokenizer\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "data_vnexpress = pd.read_csv(codecs.open('filtered_data2/vnexpress.csv','r','utf-8'))\n",
    "data_dantri = pd.read_csv(codecs.open('filtered_data2/dantri.csv','r','utf-8'))\n",
    "data_vietnamnet = pd.read_csv(codecs.open('filtered_data2/vietnamnet.csv','r','utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vnexpress.content = data_vnexpress.content.str.replace(pat=\"(\\._)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vnexpress.content = data_vnexpress.content.str.replace(pat=\"(\\d*)\", regex=True,repl=\"\")\n",
    "\n",
    "data_vnexpress.content = data_vnexpress.content.str.replace(pat=\"(\\s+[a-zA-Z]\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vnexpress.content = data_vnexpress.content.str.replace(pat=\"(\\W)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vnexpress.content = data_vnexpress.content.str.replace(pat=r\"(\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vnexpress.content = data_vnexpress.content.str.lower()\n",
    "\n",
    "data_vnexpress.to_csv(\"train_data2/vnexpress.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vietnamnet.content = data_vietnamnet.content.str.replace(pat=\"(\\._)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vietnamnet.content = data_vietnamnet.content.str.replace(pat=\"(\\d*)\", regex=True,repl=\"\")\n",
    "\n",
    "data_vietnamnet.content = data_vietnamnet.content.str.replace(pat=\"(\\s+[a-zA-Z]\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vietnamnet.content = data_vietnamnet.content.str.replace(pat=\"(\\W)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vietnamnet.content = data_vietnamnet.content.str.replace(pat=r\"(\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_vietnamnet.content = data_vietnamnet.content.str.lower()\n",
    "\n",
    "data_vietnamnet.to_csv(\"train_data2/vietnamnet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dantri.content = data_dantri.content.str.replace(pat=\"(\\._)\", regex=True,repl=\" \")\n",
    "\n",
    "data_dantri.content = data_dantri.content.str.replace(pat=\"(\\d*)\", regex=True,repl=\"\")\n",
    "\n",
    "data_dantri.content = data_dantri.content.str.replace(pat=\"(\\s+[a-zA-Z]\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_dantri.content = data_dantri.content.str.replace(pat=\"(\\W)\", regex=True,repl=\" \")\n",
    "\n",
    "data_dantri.content = data_dantri.content.str.replace(pat=r\"(\\s+)\", regex=True,repl=\" \")\n",
    "\n",
    "data_dantri.content = data_dantri.content.str.lower()\n",
    "\n",
    "data_dantri.to_csv(\"train_data2/data_dantri.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/data_dantri.csv', 'r', 'utf-8'))\n",
    "data = data.append(pd.read_csv(\n",
    "    codecs.open('train_data/vnexpress.csv', 'r', 'utf-8')),ignore_index=True)\n",
    "data.to_csv(\"train_data/train_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Chinh tri Xa hoi: 3500\n",
      "1. Cong Nghe: 3500\n",
      "2. Doi Song: 3413\n",
      "3. Du Lich: 3500\n",
      "4. Van Hoa - Giai Tri: 3500\n",
      "5. Giao Duc: 3500\n",
      "6. Khoa hoc: 3500\n",
      "7. Kinh doanh: 3500\n",
      "8. Phap Luat : 3500\n",
      "9. Suc Khoe: 3500\n",
      "10. The Gioi: 3500\n",
      "11. The Thao: 3500\n",
      "12. Xe: 3500\n",
      "----\n",
      "0. Chinh tri Xa hoi: 2494\n",
      "1. Cong Nghe: 2421\n",
      "2. Doi Song: 2400\n",
      "3. Du Lich: 2419\n",
      "4. Van Hoa - Giai Tri: 2481\n",
      "5. Giao Duc: 2451\n",
      "6. Khoa hoc: 2424\n",
      "7. Kinh doanh: 2433\n",
      "8. Phap Luat : 2441\n",
      "9. Suc Khoe: 2442\n",
      "10. The Gioi: 2466\n",
      "11. The Thao: 2500\n",
      "12. Xe: 2417\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0)]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 3500]\n",
    "         \n",
    "X, y = data.content, data.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "print('----')\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(y_train[y_train == idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.503283977508545\n"
     ]
    }
   ],
   "source": [
    "from model.nb_model import NBModel\n",
    "import pickle\n",
    "import time \n",
    "start = time.time()\n",
    "\n",
    "model = NBModel()\n",
    "clf = model.clf.fit(X_train,y_train)\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "pkl_filename = \"nb_model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.880775451660156\n"
     ]
    }
   ],
   "source": [
    "from model.randomforest_model import RandomForestModel\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = RandomForestModel()\n",
    "clf = model.clf.fit(X_train,y_train)\n",
    "\n",
    "print(time.time() - start)\n",
    "pkl_filename = \"randomforest_model.pkl\"  \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694.8184878826141\n"
     ]
    }
   ],
   "source": [
    "from model.mlp_model import    MLPModel\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "model = MLPModel()\n",
    "clf = model.clf.fit(X_train,y_train)\n",
    "pkl_filename = \"mlp_model.pkl\"\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.244611978530884\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "from model.svm_model import SVMModel\n",
    "model = SVMModel()\n",
    "clf = model.clf.fit(X_train,y_train)\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "import pickle\n",
    "pkl_filename = \"svm_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.80302166938782\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "from model.decisiontree_model import DecisionTreeModel\n",
    "model = DecisionTreeModel()\n",
    "clf = model.clf.fit(X_train,y_train)\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "import pickle\n",
    "pkl_filename = \"decisiontree_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = \"nb_model.pkl\"  \n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = \"mlp_model.pkl\"  \n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = \"randomforest_model.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = \"svm_model.pkl\"\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.utils import shuffle\n",
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0) | (data['label'] == 1.0) | (data['label'] == 2.0) ]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() > 3500]\n",
    "\n",
    "data = data.append(pd.read_csv(codecs.open('train_data2/vietnamnet.csv', 'r', 'utf-8')) ,ignore_index=True )\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 500]\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "X_test, y_test = data.content, data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(X_test)\n",
    "x['predict'] = y_pred.tolist()\n",
    "x['label']=y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = confusion_matrix(y_test,y_pred)\n",
    "df_cm = pd.DataFrame(array, index = [i[0] for i in labels],\n",
    "                  columns = [i[0] for i in labels])\n",
    "plt.figure(figsize = (10,10))\n",
    "sn.heatmap(df_cm, annot=True,fmt=\"d\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = input()\n",
    "\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "\n",
    "test_data = [{\"content\": text}\n",
    "]\n",
    "\n",
    "data = pd.DataFrame(test_data)\n",
    "data['content'] = data.apply(lambda row: word_tokenize(row['content'], format=\"text\"), axis=1)\n",
    "# print(data.loc[0]['content'])\n",
    "labels[int(clf.predict(data['content']))][0]\n",
    "# clf.predict_proba(data['content'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "f = open('vietnamese-stopwords-dash.txt', 'r')\n",
    "sw = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "cnt =CountVectorizer(min_df=5, max_df=0.7, stop_words=sw)\n",
    "Y= cnt.fit(X_test).vocabulary_\n",
    "tfidf = TfidfTransformer()\n",
    "X= tfidf.fit_transform(cnt.fit_transform(X_test))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21672\n",
      "ảnh_hưởng\n",
      "0.037789172565635465\n",
      "đức_huy\n",
      "0.039415707566969056\n",
      "đợt\n",
      "0.10467478402817157\n",
      "độ_ẩm\n",
      "0.03976873142229897\n",
      "đồng_ý\n",
      "0.02557520052144342\n",
      "đôi\n",
      "0.020158857009244985\n",
      "đánh\n",
      "0.023277363037123622\n",
      "điều_trần\n",
      "0.043941508676094296\n",
      "ôtô\n",
      "0.02652862690335716\n",
      "xảy\n",
      "0.017842162213384\n",
      "xe_hơi\n",
      "0.03204503570423849\n",
      "xe\n",
      "0.20270707823816156\n",
      "vụn\n",
      "0.04106891239965643\n",
      "vụ\n",
      "0.03621241094514442\n",
      "vỡ\n",
      "0.055234423373857824\n",
      "vận_tải\n",
      "0.06287072727799442\n",
      "vô_cùng\n",
      "0.024761608030750323\n",
      "vnexpress\n",
      "0.0237200732853307\n",
      "va_chạm\n",
      "0.03190757060970916\n",
      "túi\n",
      "0.36872397093609877\n",
      "tình_huống\n",
      "0.025362102560395672\n",
      "tuần\n",
      "0.01833016728233342\n",
      "tuyên_bố\n",
      "0.024707196459065543\n",
      "triệu_hồi\n",
      "0.5315343903770906\n",
      "triệu\n",
      "0.08898954297812096\n",
      "toàn_cầu\n",
      "0.02539212261703079\n",
      "toàn\n",
      "0.022227474619554762\n",
      "toyota\n",
      "0.03329689086662047\n",
      "tiểu_bang\n",
      "0.04313438979180819\n",
      "tiêu_dùng\n",
      "0.02677183382023403\n",
      "thừa_nhận\n",
      "0.0250122322191653\n",
      "thế_giới\n",
      "0.03123465044913235\n",
      "thượng_nghị_sĩ\n",
      "0.04214961423362034\n",
      "thông_báo\n",
      "0.045231194092005704\n",
      "thành\n",
      "0.017122744460556744\n",
      "thay_thế\n",
      "0.051129787460654844\n",
      "takata\n",
      "0.40369002966371526\n",
      "tai_nạn\n",
      "0.027409031965310807\n",
      "sự_kiện\n",
      "0.022938099673327637\n",
      "sản_xuất\n",
      "0.07783872471052092\n",
      "sản_phẩm\n",
      "0.01830640564669208\n",
      "rộng\n",
      "0.021033945320331593\n",
      "quốc\n",
      "0.030516210249417343\n",
      "quy_mô\n",
      "0.02663695041519948\n",
      "phức_tạp\n",
      "0.026248253920336344\n",
      "phạm_vi\n",
      "0.03158900251146769\n",
      "phân_tích\n",
      "0.048797053722278806\n",
      "phát_nổ\n",
      "0.042281524797133124\n",
      "phiên\n",
      "0.027603124624687454\n",
      "nặng_nề\n",
      "0.030995015857190347\n",
      "nằm\n",
      "0.05059508448516543\n",
      "nissan\n",
      "0.04202031593292142\n",
      "nhựa\n",
      "0.05993653184956106\n",
      "nhật_bản\n",
      "0.02335031743650347\n",
      "nhận_định\n",
      "0.02337236366166747\n",
      "nhtsa\n",
      "0.05001077504621015\n",
      "nguyên_nhân\n",
      "0.04350220585315783\n",
      "nguy_hiểm\n",
      "0.02389315054910411\n",
      "nghi_ngờ\n",
      "0.029462766202993262\n",
      "nghi\n",
      "0.027905530085523163\n",
      "net\n",
      "0.02539212261703079\n",
      "nam\n",
      "0.019669197040437063\n",
      "mỹ\n",
      "0.11219045656442035\n",
      "mở_rộng\n",
      "0.023394484577742593\n",
      "mắc\n",
      "0.024321458219042358\n",
      "mảnh\n",
      "0.05656961843904534\n",
      "mark\n",
      "0.04202031593292142\n",
      "malaysia\n",
      "0.030070129937991876\n",
      "lửa\n",
      "0.029808518487177332\n",
      "lỗi\n",
      "0.15332761909905468\n",
      "lịch_sử\n",
      "0.04652573893330518\n",
      "lắp\n",
      "0.06477452683562367\n",
      "lái_xe\n",
      "0.028253642808003132\n",
      "lan\n",
      "0.03156314366255494\n",
      "kim_loại\n",
      "0.06232550304864945\n",
      "khổng_lồ\n",
      "0.02719405449548023\n",
      "khả_năng\n",
      "0.01603677489672568\n",
      "không_tưởng\n",
      "0.04486266033678882\n",
      "không_khí\n",
      "0.025332219895804836\n",
      "khí\n",
      "0.3785163028741327\n",
      "khách_hàng\n",
      "0.02081138974300358\n",
      "khuyên\n",
      "0.027422706003431396\n",
      "khu_vực\n",
      "0.017105807094856283\n",
      "kelly\n",
      "0.04846730978521954\n",
      "hợp_tác\n",
      "0.04934234472636258\n",
      "hộ\n",
      "0.027803164146248872\n",
      "hơi\n",
      "0.026012430580445438\n",
      "hãng\n",
      "0.05972181798697163\n",
      "hàng_loạt\n",
      "0.024253708186372458\n",
      "hoạt_động\n",
      "0.015414026136922871\n",
      "hoàn_thành\n",
      "0.023798176499098742\n",
      "honda\n",
      "0.061755578349785414\n",
      "gửi\n",
      "0.01730910521335696\n",
      "gấp\n",
      "0.023491217470205647\n",
      "gm\n",
      "0.041893528438181615\n",
      "giải_quyết\n",
      "0.02228954115930753\n",
      "giao_thông\n",
      "0.0991559392153586\n",
      "dính\n",
      "0.030472388938512507\n",
      "dân\n",
      "0.01694155554376866\n",
      "diện\n",
      "0.08255770378533975\n",
      "cục\n",
      "0.02557520052144342\n",
      "cần_thiết\n",
      "0.02407913844116607\n",
      "cơ_quan\n",
      "0.0188355301351337\n",
      "công_tắc\n",
      "0.04593545259883916\n",
      "công_bố\n",
      "0.020977591216893906\n",
      "câu\n",
      "0.01799219545267599\n",
      "con_số\n",
      "0.05023432391157837\n",
      "chủ_động\n",
      "0.026112456634231233\n",
      "chủ_yếu\n",
      "0.022801782596527178\n",
      "chống\n",
      "0.020605800994420977\n",
      "chết\n",
      "0.06551344610167364\n",
      "chính_phủ\n",
      "0.021190157336014172\n",
      "chi_phí\n",
      "0.022358502778739405\n",
      "cao_cấp\n",
      "0.02305624974530649\n",
      "bộ_trưởng\n",
      "0.027409031965310807\n",
      "bộ_phận\n",
      "0.027167673244172064\n",
      "bắn\n",
      "0.030132019982567884\n",
      "bất_tiện\n",
      "0.040959172827959654\n",
      "bất_an\n",
      "0.04344537003234947\n",
      "bơm\n",
      "0.14595204382660254\n",
      "bung\n",
      "0.03795872503806925\n",
      "ban_đầu\n",
      "0.02297955600825343\n",
      "an_toàn\n",
      "0.05902011945717068\n",
      "[0.03778917 0.03941571 0.10467478 0.03976873 0.0255752  0.02015886\n",
      " 0.02327736 0.04394151 0.02652863 0.01784216 0.03204504 0.20270708\n",
      " 0.04106891 0.03621241 0.05523442 0.06287073 0.02476161 0.02372007\n",
      " 0.03190757 0.36872397 0.0253621  0.01833017 0.0247072  0.53153439\n",
      " 0.08898954 0.02539212 0.02222747 0.03329689 0.04313439 0.02677183\n",
      " 0.02501223 0.03123465 0.04214961 0.04523119 0.01712274 0.05112979\n",
      " 0.40369003 0.02740903 0.0229381  0.07783872 0.01830641 0.02103395\n",
      " 0.03051621 0.02663695 0.02624825 0.031589   0.04879705 0.04228152\n",
      " 0.02760312 0.03099502 0.05059508 0.04202032 0.05993653 0.02335032\n",
      " 0.02337236 0.05001078 0.04350221 0.02389315 0.02946277 0.02790553\n",
      " 0.02539212 0.0196692  0.11219046 0.02339448 0.02432146 0.05656962\n",
      " 0.04202032 0.03007013 0.02980852 0.15332762 0.04652574 0.06477453\n",
      " 0.02825364 0.03156314 0.0623255  0.02719405 0.01603677 0.04486266\n",
      " 0.02533222 0.3785163  0.02081139 0.02742271 0.01710581 0.04846731\n",
      " 0.04934234 0.02780316 0.02601243 0.05972182 0.02425371 0.01541403\n",
      " 0.02379818 0.06175558 0.01730911 0.02349122 0.04189353 0.02228954\n",
      " 0.09915594 0.03047239 0.01694156 0.0825577  0.0255752  0.02407914\n",
      " 0.01883553 0.04593545 0.02097759 0.0179922  0.05023432 0.02611246\n",
      " 0.02280178 0.0206058  0.06551345 0.02119016 0.0223585  0.02305625\n",
      " 0.02740903 0.02716767 0.03013202 0.04095917 0.04344537 0.14595204\n",
      " 0.03795873 0.02297956 0.05902012]\n"
     ]
    }
   ],
   "source": [
    "print(len(cnt.fit(X_test).vocabulary_))\n",
    "for i in range(len(X[1].indices)):\n",
    "    print(list(Y.keys())[list(Y.values()).index(X[1].indices[i])])\n",
    "    print(X[1].data[i])\n",
    "print(X[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
