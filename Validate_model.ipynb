{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Chinh tri Xa hoi: 500\n",
      "1. Cong Nghe: 500\n",
      "2. Doi Song: 500\n",
      "3. Du Lich: 500\n",
      "4. Van Hoa - Giai Tri: 500\n",
      "5. Giao Duc: 500\n",
      "6. Khoa hoc: 500\n",
      "7. Kinh doanh: 500\n",
      "8. Phap Luat : 500\n",
      "9. Suc Khoe: 500\n",
      "10. The Gioi: 500\n",
      "11. The Thao: 500\n",
      "12. Xe: 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.utils import shuffle\n",
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0) | (data['label'] == 1.0) | (data['label'] == 2.0) ]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() > 3500]\n",
    "\n",
    "data = data.append(pd.read_csv(codecs.open('train_data/vietnamnet.csv', 'r', 'utf-8')) ,ignore_index=True )\n",
    "# data = pd.read_csv(codecs.open('train_data/vietnamnet.csv', 'r', 'utf-8')) \n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 500]\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "X_test2, y_test2 = data.content, data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Chinh tri Xa hoi: 3500\n",
      "1. Cong Nghe: 3500\n",
      "2. Doi Song: 3413\n",
      "3. Du Lich: 3500\n",
      "4. Van Hoa - Giai Tri: 3500\n",
      "5. Giao Duc: 3500\n",
      "6. Khoa hoc: 3500\n",
      "7. Kinh doanh: 3500\n",
      "8. Phap Luat : 3500\n",
      "9. Suc Khoe: 3500\n",
      "10. The Gioi: 3500\n",
      "11. The Thao: 3500\n",
      "12. Xe: 3500\n",
      "----\n",
      "0. Chinh tri Xa hoi: 2494\n",
      "1. Cong Nghe: 2420\n",
      "2. Doi Song: 2391\n",
      "3. Du Lich: 2422\n",
      "4. Van Hoa - Giai Tri: 2476\n",
      "5. Giao Duc: 2455\n",
      "6. Khoa hoc: 2462\n",
      "7. Kinh doanh: 2443\n",
      "8. Phap Luat : 2445\n",
      "9. Suc Khoe: 2444\n",
      "10. The Gioi: 2469\n",
      "11. The Thao: 2506\n",
      "12. Xe: 2362\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0)]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 3500]\n",
    "         \n",
    "X, y = data.content, data.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "print('----')\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(y_train[y_train == idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# model_choose = input(\"Choose model: \\n1: Naives Bayes\\n2: MLP\\n3: RandomForest\\n4: SVM\\n5: Decision Tree\\n\")\n",
    "# i = int(model_choose)\n",
    "filenames = {\n",
    "     1 : \"nb_model.pkl\",\n",
    "#     2 : \"mlp_model.pkl\",\n",
    "    3 : \"randomforest_model.pkl\",\n",
    "    4 : \"svm_model.pkl\",\n",
    "    5: \"decisiontree_model.pkl\",\n",
    "}\n",
    "models = {\n",
    "     1 : \"naive bayes       \",\n",
    "#     2 : \"MLP                      \",\n",
    "    3 : \"Random Forest \",\n",
    "    4 : \"SVM                      \",\n",
    "    5: \"Decision tree      \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data\n",
      "naive bayes        0.8442543018025103\n",
      "MLP                       0.9323665418855579\n",
      "Random Forest  0.9285916512001007\n",
      "SVM                       0.938311994715153\n",
      "Decision tree       0.859385321966718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Train Data\")\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_train)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_train, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data\n",
      "naive bayes        0.844906048150323\n",
      "MLP                       0.9349677040516735\n",
      "Random Forest  0.9310041103934233\n",
      "SVM                       0.9393716970052848\n",
      "Decision tree       0.8588520258367587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Test Data\")\n",
    "\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data 2\n",
      "naive bayes        0.842\n",
      "MLP                       0.9110769230769231\n",
      "Random Forest  0.9190769230769231\n",
      "SVM                       0.9301538461538461\n",
      "Decision tree       0.8315384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Test Data 2\")\n",
    "\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_test2, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose model: \n",
      "1: Naives Bayes\n",
      "2: MLP\n",
      "3: RandomForest\n",
      "4: SVM\n",
      "5: Decision Tree\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75      1006\n",
      "         1.0       0.93      0.85      0.89      1080\n",
      "         2.0       0.68      0.69      0.68      1022\n",
      "         3.0       0.81      0.88      0.84      1078\n",
      "         4.0       0.91      0.87      0.89      1024\n",
      "         5.0       0.85      0.92      0.89      1045\n",
      "         6.0       0.91      0.73      0.81      1038\n",
      "         7.0       0.78      0.70      0.74      1057\n",
      "         8.0       0.83      0.94      0.88      1055\n",
      "         9.0       0.80      0.89      0.84      1056\n",
      "        10.0       0.86      0.85      0.85      1031\n",
      "        11.0       0.94      0.98      0.96       994\n",
      "        12.0       0.94      0.94      0.94      1138\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     13624\n",
      "   macro avg       0.85      0.84      0.84     13624\n",
      "weighted avg       0.85      0.84      0.84     13624\n",
      "\n",
      "naive bayes        0.844906048150323\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "model_choose = input(\"Choose model: \\n1: Naives Bayes\\n2: MLP\\n3: RandomForest\\n4: SVM\\n5: Decision Tree\\n\")\n",
    "i = int(model_choose)\n",
    "filenames = {\n",
    "     1 : \"nb_model.pkl\",\n",
    "#     2 : \"mlp_model.pkl\",\n",
    "    3 : \"randomforest_model.pkl\",\n",
    "    4 : \"svm_model.pkl\",\n",
    "    5: \"decisiontree_model.pkl\",\n",
    "}\n",
    "models = {\n",
    "     1 : \"naive bayes       \",\n",
    "#     2 : \"MLP                      \",\n",
    "    3 : \"Random Forest \",\n",
    "    4 : \"SVM                      \",\n",
    "    5: \"Decision tree      \",\n",
    "}\n",
    "pkl_filename = filenames[i]\n",
    "\n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    clf = pickle.load(file)\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(models[i], accuracy_score(y_test, y_pred))  \n",
    "# array = confusion_matrix(y_test2,y_pred)\n",
    "# df_cm = pd.DataFrame(array, index = [i[0] for i in labels],\n",
    "#                   columns = [i[0] for i in labels])\n",
    "# plt.figure(figsize = (10,8))\n",
    "# sn.heatmap(df_cm, annot=True,fmt=\"d\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loài cây \"hoa hậu\" mang nhan sắc rực rỡ Loài cây này không chỉ là một trong những cây cao nhất thế giới mà còn khiến tất cả ấn tượng vì vỏ cây rực rỡ sắc màu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Khoa hoc'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from underthesea import word_tokenize\n",
    "text = input()\n",
    "\n",
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "test_data = [{\"content\": text}\n",
    "]\n",
    "\n",
    "data = pd.DataFrame(test_data)\n",
    "data['content'] = data.apply(lambda row: word_tokenize(row['content'], format=\"text\"), axis=1)\n",
    "# print(data.loc[0]['content'])\n",
    "labels[int(clf.predict(data['content']))][0]\n",
    "# clf.predict_proba(data['content'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
