{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Chinh tri Xa hoi: 500\n",
      "1. Cong Nghe: 500\n",
      "2. Doi Song: 500\n",
      "3. Du Lich: 500\n",
      "4. Van Hoa - Giai Tri: 500\n",
      "5. Giao Duc: 500\n",
      "6. Khoa hoc: 500\n",
      "7. Kinh doanh: 500\n",
      "8. Phap Luat : 500\n",
      "9. Suc Khoe: 500\n",
      "10. The Gioi: 500\n",
      "11. The Thao: 500\n",
      "12. Xe: 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.utils import shuffle\n",
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0) | (data['label'] == 1.0) | (data['label'] == 2.0) ]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() > 3500]\n",
    "\n",
    "data = data.append(pd.read_csv(codecs.open('train_data/vietnamnet.csv', 'r', 'utf-8')) ,ignore_index=True )\n",
    "# data = pd.read_csv(codecs.open('train_data/vietnamnet.csv', 'r', 'utf-8')) \n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 500]\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "X_test2, y_test2 = data.content, data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Chinh tri Xa hoi: 3500\n",
      "1. Cong Nghe: 3500\n",
      "2. Doi Song: 3413\n",
      "3. Du Lich: 3500\n",
      "4. Van Hoa - Giai Tri: 3500\n",
      "5. Giao Duc: 3500\n",
      "6. Khoa hoc: 3500\n",
      "7. Kinh doanh: 3500\n",
      "8. Phap Luat : 3500\n",
      "9. Suc Khoe: 3500\n",
      "10. The Gioi: 3500\n",
      "11. The Thao: 3500\n",
      "12. Xe: 3500\n",
      "----\n",
      "0. Chinh tri Xa hoi: 2494\n",
      "1. Cong Nghe: 2423\n",
      "2. Doi Song: 2397\n",
      "3. Du Lich: 2418\n",
      "4. Van Hoa - Giai Tri: 2476\n",
      "5. Giao Duc: 2457\n",
      "6. Khoa hoc: 2441\n",
      "7. Kinh doanh: 2441\n",
      "8. Phap Luat : 2449\n",
      "9. Suc Khoe: 2447\n",
      "10. The Gioi: 2464\n",
      "11. The Thao: 2503\n",
      "12. Xe: 2379\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv(\n",
    "    codecs.open('train_data/train_data.csv', 'r', 'utf-8'))\n",
    "\n",
    "df = data[(data['label'] == 6.0) | (data['label'] == 12.0)]\n",
    "df=df.append(df, ignore_index=True)\n",
    "df = shuffle(df)\n",
    "data = data.append(df,ignore_index=True)\n",
    "\n",
    "data = data.loc[data.sample(frac=1).groupby('label').cumcount() < 3500]\n",
    "         \n",
    "X, y = data.content, data.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(data[data.label == idx])))\n",
    "print('----')\n",
    "for label, idx in labels:\n",
    "    print('%d. %s: %d' % (idx, label,len(y_train[y_train == idx])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# model_choose = input(\"Choose model: \\n1: Naives Bayes\\n2: MLP\\n3: RandomForest\\n4: SVM\\n5: Decision Tree\\n\")\n",
    "# i = int(model_choose)\n",
    "filenames = {\n",
    "     1 : \"nb_model.pkl\",\n",
    "#     2 : \"mlp_model.pkl\",\n",
    "    3 : \"randomforest_model.pkl\",\n",
    "    4 : \"svm_model.pkl\",\n",
    "    5: \"decisiontree_model.pkl\",\n",
    "}\n",
    "models = {\n",
    "     1 : \"naive bayes       \",\n",
    "#     2 : \"MLP                      \",\n",
    "    3 : \"Random Forest \",\n",
    "    4 : \"SVM                      \",\n",
    "    5: \"Decision tree      \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data\n",
      "naive bayes        0.8442543018025103\n",
      "MLP                       0.9323665418855579\n",
      "Random Forest  0.9285916512001007\n",
      "SVM                       0.938311994715153\n",
      "Decision tree       0.859385321966718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Train Data\")\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_train)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_train, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data\n",
      "naive bayes        0.844906048150323\n",
      "MLP                       0.9349677040516735\n",
      "Random Forest  0.9310041103934233\n",
      "SVM                       0.9393716970052848\n",
      "Decision tree       0.8588520258367587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Test Data\")\n",
    "\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data 2\n",
      "naive bayes        0.842\n",
      "MLP                       0.9110769230769231\n",
      "Random Forest  0.9190769230769231\n",
      "SVM                       0.9301538461538461\n",
      "Decision tree       0.8315384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Accuracy of Test Data 2\")\n",
    "\n",
    "for i in filenames:\n",
    "    pkl_filename = filenames[i]\n",
    "\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        clf = pickle.load(file)\n",
    "    y_pred = clf.predict(X_test2)\n",
    "\n",
    "    \n",
    "    # print(confusion_matrix(y_test,y_pred))  \n",
    "    # print(classification_report(y_test,y_pred))  \n",
    "    print(models[i], accuracy_score(y_test2, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose model: \n",
      "1: Naives Bayes\n",
      "2: MLP\n",
      "3: RandomForest\n",
      "4: SVM\n",
      "5: Decision Tree\n",
      "4\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  Chinh tri Xa hoi       0.88      0.89      0.88      1006\n",
      "         Cong Nghe       0.96      0.96      0.96      1077\n",
      "          Doi Song       0.85      0.89      0.87      1016\n",
      "           Du Lich       0.94      0.95      0.94      1082\n",
      "Van Hoa - Giai Tri       0.96      0.94      0.95      1024\n",
      "          Giao Duc       0.96      0.95      0.95      1043\n",
      "          Khoa hoc       0.95      0.95      0.95      1059\n",
      "        Kinh doanh       0.90      0.80      0.85      1059\n",
      "        Phap Luat        0.95      0.97      0.96      1051\n",
      "          Suc Khoe       0.92      0.96      0.94      1053\n",
      "          The Gioi       0.97      0.94      0.95      1036\n",
      "          The Thao       0.98      0.99      0.99       997\n",
      "                Xe       0.97      1.00      0.99      1121\n",
      "\n",
      "         micro avg       0.94      0.94      0.94     13624\n",
      "         macro avg       0.94      0.94      0.94     13624\n",
      "      weighted avg       0.94      0.94      0.94     13624\n",
      "\n",
      "SVM                       0.9371697005284791\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "model_choose = input(\"Choose model: \\n1: Naives Bayes\\n2: MLP\\n3: RandomForest\\n4: SVM\\n5: Decision Tree\\n\")\n",
    "i = int(model_choose)\n",
    "filenames = {\n",
    "     1 : \"nb_model.pkl\",\n",
    "#     2 : \"mlp_model.pkl\",\n",
    "    3 : \"randomforest_model.pkl\",\n",
    "    4 : \"svm_model.pkl\",\n",
    "    5: \"decisiontree_model.pkl\",\n",
    "}\n",
    "models = {\n",
    "     1 : \"naive bayes       \",\n",
    "#     2 : \"MLP                      \",\n",
    "    3 : \"Random Forest \",\n",
    "    4 : \"SVM                      \",\n",
    "    5: \"Decision tree      \",\n",
    "}\n",
    "pkl_filename = filenames[i]\n",
    "\n",
    "with open(pkl_filename, 'rb') as file: \n",
    "    clf = pickle.load(file)\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(confusion_matrix(y_test,y_pred))  \n",
    "labels = [\n",
    "'Chinh tri Xa hoi',\n",
    "'Cong Nghe',\n",
    "'Doi Song',\n",
    "'Du Lich',\n",
    "'Van Hoa - Giai Tri',\n",
    "'Giao Duc',\n",
    "'Khoa hoc',\n",
    "'Kinh doanh',\n",
    "'Phap Luat ',\n",
    "'Suc Khoe',\n",
    "'The Gioi',\n",
    "'The Thao',\n",
    "'Xe',\n",
    "]\n",
    "print(classification_report(y_test,y_pred,target_names=labels))  \n",
    "print(models[i], accuracy_score(y_test, y_pred))  \n",
    "# array = confusion_matrix(y_test2,y_pred)\n",
    "# df_cm = pd.DataFrame(array, index = [i[0] for i in labels],\n",
    "#                   columns = [i[0] for i in labels])\n",
    "# plt.figure(figsize = (10,8))\n",
    "# sn.heatmap(df_cm, annot=True,fmt=\"d\",cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7692)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7469)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2353)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:8007)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-67f2360854f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munderthesea\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m labels = [\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from underthesea import word_tokenize\n",
    "text = input()\n",
    "\n",
    "labels = [\n",
    "('Chinh tri Xa hoi', 0),\n",
    "('Cong Nghe', 1),\n",
    "('Doi Song', 2),\n",
    "('Du Lich', 3),\n",
    "('Van Hoa - Giai Tri', 4),\n",
    "('Giao Duc', 5),\n",
    "('Khoa hoc', 6),\n",
    "('Kinh doanh', 7),\n",
    "('Phap Luat ', 8),\n",
    "('Suc Khoe', 9),\n",
    "('The Gioi', 10),\n",
    "('The Thao', 11),\n",
    "('Xe', 12),\n",
    "]\n",
    "test_data = [{\"content\": text}\n",
    "]\n",
    "\n",
    "data = pd.DataFrame(test_data)\n",
    "data['content'] = data.apply(lambda row: word_tokenize(row['content'], format=\"text\"), axis=1)\n",
    "# print(data.loc[0]['content'])\n",
    "labels[int(clf.predict(data['content']))][0]\n",
    "# clf.predict_proba(data['content'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
